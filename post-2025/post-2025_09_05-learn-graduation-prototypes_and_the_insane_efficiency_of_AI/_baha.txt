[div][size=6][b]【專題】系統原型和 AI 的瘋狂效率[/b][/size][/div][div]九月第一週就追加更新，欸嘿 (ゝω・)╭☆[/div]
[div][/div][div][/div][div]這些原本要寫在十月的【學習】裡，但發現篇幅夠了就先發，這篇算是八月中到現在，大概半個月的專題程式內容，還有一些目前為止對 VibeCodeing （或稱 AI Assisted Coding）的心得。[/div]
[div][/div][div][/div][div]開始前，先讓我粗暴的介紹遊戲，我們要做一款 2.5D 的動作 Rogue 遊戲。[/div]
[div][/div][div][/div][div]先上成果，總之玩家有根棍子，除了打人以外，還可以丟出去插在敵人身上，然後把敵人拿起來當武器用。鬼轉吃毒動作遊戲，想不到吧 (ﾟ∀ﾟ)[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_8.jpg][/div][/div][/div]
[div][/div][div][/div][div]想知道是怎麼演變成現在的樣子就等之後【專題】的企劃篇吧 :P[/div]
[div][size=5][b]AI 輔助開發[/b][/size][/div][div]之前一段時間我都比較優先架構、框架或基本結構架起來再處理回饋跟視覺，想說這些等比較後面再串就好，一些基本架構也不會碰到回饋相關功能。[/div]
[div][/div][div][/div][div]只有自己的時候這樣沒什麼問題吧，畢竟我能預期最後補上回饋時遊戲會有的樣子。[/div]
[div][/div][div][/div][div]但團隊就不太一樣了，我之前沒意識到看不看的到東西對「士氣」的影響有多大，尤其對專題團隊而言，不是所有人都有能力預知專案最後的樣子，這會需要一些製作經驗。[/div]
[div][/div][div][/div][div]所以畢專就不特別管架構或啥，省下時間先直衝能見、能玩、能感覺到的東西出來，屎山也行，有時間再回來修就好。[/div]
[div][/div][div][/div][div]至少我原本是這樣想的。[/div]
[div][/div][div][/div][div]不過暑假的 Vibe Coding 體驗讓我看到一個機會，依靠 AI 的可怕效率或許能兼顧兩者，寫出有長期維護價值的程式碼，也沒失去一點原型開發應有的效率。[/div]
[div][b]※回顧舊觀點[/b][/div][div]開始前先回顧上篇【學習】中提到用 AI 的幾大重點：[/div]
[ul]
[li]在目標與意圖足夠明確時，AI 程式除了快之外還能寫比我好[/li]
[li]讓 AI 幫忙主要是為了提高效率而已，自己還是要有能力解決問題[/li]
[li]利用 AI 可以很激進的擴展能力（知識）邊界[/li]
[li][b]自身的能力邊界就是 AI 的表現邊界[/b][/li]
[li][b]可以利用 AI 擴展自身能力邊界，再讓 AI 用瘋狂的效率完成自己能力邊界内的工作，產生一種正循環[/b][/li]
[/ul]
[div][b]※新心得[/b][/div][div]開始前也先提這篇的心得，大致與前面相同，只是多了一些補充，以下是針對目前單人程式 + AI 輔助的開發的總結：[/div]
[ul]
[li]95% 的 AI 程式碼是 GPT 寫的，其他 CodexCLI, GeminiCLI, Copilot Agent 總計不到 5%[/li]
[li]AI 程式碼與手工程式碼大約各占 50%，AI 主要負責各種相互獨立的模組系統框架，自己則是針對遊戲需求進行實做與各系統的整合。[/li]
[li][b]Context 的限制導致 AI 不適合大規模的整合工作。[/b][/li]
[li][b]把工作拆的越單元、模組化，AI 的表現也會越精準。[/b][/li]
[/ul]
[div][/div][div][/div][div]後面開始講一些實際程式的東西吧，不是什麼教學或指南，也沒有要賣課，只是分享一下我「目前」最適應方法，要做某個新系統時流程大概是這樣：[/div]
[ul]
[li]簡單描述需求，讓 GPT 提出多種方案[/li]
[li]自己評估哪種方案適合，要不要混合方案[/li]
[li]讓 GPT 針對指定方案提出一些實做案例，或開始生成[/li]
[li][b]如果生成內容超出能力邊界，讓 GPT 進一步解釋原理[/b][/li]
[li]檢查生成內容，評估是不是符合需求，有沒有缺少或過度設計，讓 GPT 調整[/li]
[li]把程式碼貼到專案中，然後根據專案修改和二次評估，如果理想就繼續沿用[/li]
[li]如果不理想，先用自己的意思把程式碼整理後，再丟給另一個對話串[/li]
[li][b]視情況回到前面的某個步驟，重複循環直到結果貼近自己預期的樣子，或在某個時機接手修改[/b][/li]
[/ul]
[div][b]※注意事項：[/b][/div]
[ul]
[li]後續部分會省略基礎的 SOLID 知識[/li]
[li]如果文中說我「直接」怎樣，那不是真的直接，而是我主觀上的直接，當中可能包括一些我已經習慣但至關重要的細節沒提。[/li]
[li]後面會在每個部分備註使用 AI 的比率，數值指的是程式碼「最終樣貌」中由 AI 編寫的比率估計，當中「不包括討論、重構和調整過程捨棄的『巨量』內容  」，也不包括手動編寫時 Copilot 跳出的 Auto Complete 提示。[/li]
[li]編排不完全依據實際時間軸，有根據文章架構微調[/li]
[li]這篇過程的很多 GPT 對話忘了保留，所以只有結果，我之後會記得用封存而不是刪除 D:[/li]
[/ul]
[div][size=4][b]輸入系統（95% AI）[/b][/size][/div][div]輸入系統，化成灰都能認得的需求，但解決方案各有不同，要用新舊版的 InputSystem？還是用經典的 Input.GetKey 方案？要支援把手嗎？鍵位要怎麼擺放？[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_94.jpg][/div][/div][/div]
[div][/div][div][/div][div]具體的做法其實不重要，因為無論用哪種方案，輸入跟遊戲之間都應該擋一個接口做抽象化。比較好的做法是讓遊戲系統依賴抽象的接口，而非某個具體的解決方案。[/div]
[div][/div][div][/div][div]總之，我直接把討論時列的操作需求貼給 AI，要他生了遊戲用的輸入接口。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_10.jpg][/div][/div][/div]
[div][/div][div][/div][div]然後補充輸入系統的框架，包括抽象接口、按鈕判斷邏輯、攝影機來源、游標點擊和工廠等。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_21.jpg][/div][/div][/div]
[div][/div][div][/div][div]然後是具體的輸入方案實現，有接口之後也讓 AI 生成各種輸入方案的實作，包括一個舊版鍵鼠 Input, 和三個使用 NewInputSystem 的方案（硬編碼鍵盤、硬編碼搖桿、InputAsset）。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_32.jpg][/div][/div][/div]
[div][/div][div][/div][div]然後讓 GPT 生成一個能顯示輸入狀態的 GUI 做手動測試，這樣不用任何角色就能測各種輸入方案是否正常運作了。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_43.jpg][/div][/div][/div]
[div][/div][div][/div][div]有這個接口，之後要用其他方案，或串接外部的插件都不是問題。[/div]
[div][size=4][b]狀態機框架（80% AI）[/b][/size][/div][div]目前遊戲中最的系統，但因為也沒留到紀錄，所以只有上篇文就用過的截圖。剛開始是想直接做 PlayerController ，我把前面的 Input 腳本丟給 GPT，要他給我一些實現方案。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_54.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]但發現需求並沒那麼單純，隨著討論到後面，目標直接擴展成狀態機，而 GPT 也因為 Context 汙染而開始爆走。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_65.jpg][/div][/div][/div]
[div][/div][div][/div][div]所以我把過程的腳本重新整理後，開新對話再讓 GPT 生成，這次方向就穩定多了，目標也更明確，所以就開始擴大到把預期功能完成。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_76.jpg][/div][/div][/div]
[div][/div][div][/div][div]首先是狀態本體 StateBase，裡面包括可以被覆寫的 OnInitial, OnEnter, OnTick, OnExit 和 OnAlwaysTick ，後續所有狀態的實作都會繼承它。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_87.jpg][/div][/div][/div]
[div][/div][div][/div][div]狀態轉換條件 ITransitionCondition，用來實作狀態間的切換邏輯，回傳 true 代表條件通過。一個 Transition 可以有多個條件，例如 StateA to StateB 可以要求 ConditionA, B, C 全通過才轉換。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_93.jpg][/div][/div][/div]
[div][/div][div][/div][div]狀態的外掛插件 IStateAddon，它不會進入狀態的 State Graph，而是用掛載的方式運行。觸發時機有很多種，可以自行選用需要的介面實作，維持介面隔離 Interface Segregation。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_11.jpg][/div][/div][/div]
[div][/div][div][/div][div]狀態機的內部溝通資訊 IStateContext ，用來給狀態、條件和插件做內部溝通，包括靜態的 Config 與動態的 Runtime 參數。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_12.jpg][/div][/div][/div]
[div][/div][div][/div][div]然後狀態機的內部「不進行任何事件廣播」，Transition 條件也完全依靠動態參數判斷，跟 Unity Animator 一樣。（九日演講也說是依靠動態參數判斷，事件在狀態機中真的太難除錯）[/div]
[div][/div][div][/div][div]StateMachine 本體很乾淨，只對外部使用者提供的公開建構子、初始化、開始運作以及更新用的 Tick。（還有除錯用的快照資訊）[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_13.jpg][/div][/div][/div]
[div][/div][div][/div][div]Tick 更新流程：外掛插件的 BeforeTick 更新 > 當前狀態的 Tick > 所有狀態的 Always Tick > 外掛插件的 AfterTick > 檢查轉換 > 轉換流程 > 紀錄除錯資訊。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_14.jpg][/div][/div][/div]
[div][/div][div][/div][div]轉換流程：當前狀態的 OnExit 觸發 > Addon 的 OnExit 觸發 > 切換狀態 > Addon OnTransition > 當前狀態的 OnEnter > Addon 的 OnEnter。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_15.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]註：這裡的 events 是廣播給狀態機外部的。[/div]
[div][size=4][b]玩家控制實做 ( < 5% AI）[/b][/size][/div][div]上面只是框架，接下來是實做的玩家控制和移動部分。首先是靜態配置和動態參數，包括攻擊、位移、翻滾的配置，以及運行時狀態的參數，如行動意圖、移動請求等。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_16.jpg][/div][/div][/div]
[div][/div][div][/div][div]狀態實做，閒置、攻擊、翻滾、移動等，狀態會根據配置和動態參數，再把計算結果寫回另一個動態參數，但本身不「執行」攻擊傷害輸出或移動。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_17.jpg][/div][/div][/div]
[div][/div][div][/div][div]移動或攻擊我交給 Addon ，讓 Mover Addon 讀取動態參數中的移動請求後，再傳遞給 Unity Rigidbody 執行移動。行動的冷卻原本也寫用 Addon 處理，但後來移到狀態本體去了。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_18.jpg][/div][/div][/div]
[div][/div][div][/div][div]玩家輸入則透過一個轉換器，把輸入資訊轉換成狀態機參數，後來也把它改成 Addon 了。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_19.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]轉換條件實做，讀取配置和動態參數判斷條件是否符合。包括檢查是否進入移動狀態、是否翻滾、是否攻擊和當前狀態是否結束。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_20.jpg][/div][/div][/div]
[div][/div][div][/div][div]最後用一個 Builder 模式組裝出整個狀態機，這才是架構中最強的部分吧。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_22.jpg][/div][/div][/div]
[div][/div][div][/div][div]這個狀態機是完全模組化的，要擴展或替換某部分都很容易，而雖然現在是用程式組裝，但只要寫個轉換器就能用 ScriptableObject 或其他純資料格式組裝。[/div]
[div][size=4][b]狀態機除錯（90% AI）[/b][/size][/div][div]最後就是加上 Input 的測試，弄一個可以移動、衝刺和攻擊的小方塊，也讓 GPT 寫了 GUI Panel 方便除錯。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_23.jpg][/div][/div][/div]
[div][/div][div][/div][div]單元測試，也是 GPT 寫的，主要是針對 Builder 跟轉換條件測試。原本還有針對 State 和 StateMachine 本體運作的測試，但後來有改進一些架構，測試壞掉懶得修就算了。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_24.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]後面串接更完整人物控制時發現 GUI 不好閱讀，所以改用 Editor window，能顯示更完整的除錯資訊，包括狀態資訊、轉換資訊、條件的判斷狀態等等。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_1.jpg][/div][/div][/div]
[div][/div][div][/div][div]特別做這個 Editor window （當然也是 AI 做的）是因為我花了半天找一個手動測試時遇到的不存在的 bug，原本以為是轉換判定有誤、Builder 沒組裝正確或狀態機流程有問題。[/div]
[div][/div][div][/div][div]但單元測試全綠燈， 還仔細 Re 過幾次，檢查是不是 GPT 測試覆蓋不完全，還是有哪裡寫錯。[/div]
[div][/div][div][/div][div]結果都沒有，最後發現是「我的」手動測試的腳本寫錯，組裝狀態機的時候不小心多設一條比較寬鬆的條件沒注意到，中風==[/div]
[div][/div][div][/div][div]所以多了這個除錯視窗，後續除錯輕鬆多了。[/div]
[div][/div][div][/div][div]老實說，這是我第一次建這種狀態機，不然以前為了省事都是用 Enum Switch 方案搞定一切，但有這個之後也能用在其他地方。[/div]
[div][size=4][b]框架，回饋系統（80% AI）[/b][/size][/div][div]音效、特效、震動、停頓之類的回饋，這次先處理了回饋系統框架，因為前面說過的士氣問題。[/div]
[div][/div][div][/div][div]回饋也有各種方案，震動要用預設 Camera 還是 CinemaMachine？特效要不要物件池？音效怎麼播放？要有統一的時間管理器嗎？[/div]
[div][/div][div][/div][div]其實跟處理 Input 時一樣，具體的實現方案都不是重點，重點是接口的規範以及要選擇不同方案時的可擴展性。[/div]
[div][/div][div][/div][div]我之前的做法應該是各自實做每個系統，需要時再各自觸發吧。但這次我要改用一個統一的回饋觸發系統，接口簡化到使用者只需要傳入一個 key 就好（和可選的 Context 參數）。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_25.jpg][/div][/div][/div]
[div][/div][div][/div][div]要執行什麼效果？透過外部的配置文件定義。要怎麼執行？讓每個專案各自實做和註冊就好，擴展接口有三個：定義資料格式、定義資料來源和效果執行器。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_26.jpg][/div][/div][/div]
[div][/div][div][/div][div]假設定義一個回饋為 “Hit.Crit” ，裡面包括一個音效回饋 (audioFeedbackData) 和震動回饋 (ShadeFeedbackData)，那當使用者觸發 Hit.Crit 時，系統就會檢查有沒有註冊的執行器，然後把對應 Data 交給執行器播放回饋。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_27.jpg][/div][/div][/div]
[div][/div][div][/div][div]這樣的好處是框架本身不用提供任何解決方案，也不綁死任何實做，資料來源很自由，可以程式硬編碼、用 ScriptableObject 定義或載入 Google Sheet。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_28.jpg][/div][/div][/div]
[div][/div][div][/div][div]執行器也是，專案只要透過繼承 IFeedbackExecutor ，透過泛型 <T> 指定執行的回饋類型，就能實現不同的方案。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_29.jpg][/div][/div][/div]
[div][/div][div][/div][div]最棒的是，這套框架可以兼容幾乎任何現成的解決方案，他只規範了程式端調用的規則，專案可以根據需求實做，就算要串接插件也行。[/div]
[div][/div][div][/div][div]這裡就插上了一個 AssetStore 買的插件 [Feel](https://assetstore.unity.com/packages/tools/particles-effects/feel-183370)，裡面集成了超大量的回饋效果「實做」，包括音效、震動、時間效果或 Transform 效果等等。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_30.jpg][/div][/div][/div]
[div][/div][div][/div][div]比較麻煩的是，有些情況要共用回饋執行器，像是全域的音效播放、粒子特效等等，但有些回饋是每個物件要各自執行的，像是物體幀動、拉伸等。[/div]
[div][/div][div][/div][div]所以我用修飾模式（Decorator pattern）做了一個可覆寫的執行器註冊器，每個物件可以把各自執行的回饋覆寫進註冊器，執行時會優先選擇覆寫方案，找不到執行器才會使用共享的。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_31.jpg][/div][/div][/div]
[div][/div][div][/div][div]測試案例的執行，兩個方塊都觸發 “Hit.Crit” ，會播放共享的 Audio Feedback，但 Transform 回饋是執行各自的覆寫。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_6.jpg][/div][/div][/div]
[div][size=4][b]帳簿系統 （90% AI）[/b][/size][/div][div]就是血量、屬性、資源或其他啥的數值管理系統，跟 GPT 討論後決定做一個更通用的「數值帳簿」，裡面只做最基礎的加減紀錄，具體用途交給每個專案自己決定。[/div]
[div][/div][div][/div][div]這個其實討論蠻長的，好像捨棄了四五次討論後開始上軌道吧，也沒留到對話紀錄 DDD:[/div]
[div][/div][div][/div][div]系統的核心就是負責管理單一數值資源的 Account ，以及負責管理多個 Account 的 Ledger 。裡面有註冊參數、設置範圍和修改數值的功能。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_33.jpg][/div][/div][/div]
[div][/div][div][/div][div]也有事件監聽功能，可以訂閱某個 Accout 內容發生變化時發佈廣播。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_34.jpg][/div][/div][/div]
[div][/div][div][/div][div]一樣讓 GPT 補了除錯面板，可以看到看到註冊的 Account 內容，還有監聽中的事件。（我都不知道可以用 [CallerMemberName] 追蹤函式的調用者）[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_35.jpg][/div][/div][/div]
[div][/div][div][/div][div]單元測試，就是一些基本操作，註冊、設置範圍、修改數值，批次操作和事件監聽的測試。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_36.jpg][/div][/div][/div]
[div][size=4][b]屬性狀態 Stats 系統 ( < 5% AI )[/b][/size][/div][div]就是直接拿上面的 Ledger 實做的 Stats 系統，但因為企劃部分還沒設計完整，所以就先加個血量意思意思。後續要補上金錢、魔力或啥的都很簡單，多註冊一個就好。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_37.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]血量系統則透過 IEntityStats 接口訪問血量數值，避免直接碰觸原始的數值帳本。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_38.jpg height=350][/div][/div][/div]
[div][size=4][b]視覺容器 ( 10 % AI )[/b][/size][/div][div]因為遊戲要用 2.5D 紙片人顯示，所以讓 GPT 幫我寫了幾種紙片物件的顯示方式，無旋轉、Billboard、水平 Billboard、Z 軸朝上等等，可以根據需求切換模式。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_39.jpg][/div][/div][/div]
[div][/div][div][/div][div]然後是串起敵人的部分，為了有比較好的串接效果，我花一些時間做實驗，構想物件的 Transform 運作流程。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_40.jpg][/div][/div][/div]
[div][/div][div][/div][div]然後讓 GPT 寫一個讓平面根據相交軸旋轉的算法，整合進自己的 Util 方便後續調用。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_7.jpg][/div][/div][/div]
[div][/div][div][/div][div]剛好武器飛行時會是 Z Up，而生物會是指向攝影機的 45 度 billboard，武器可以直接插進生物的紙片 Sprite，所以只要玩家撿起來時把夾角縮小，就能維持穿刺的視覺效果。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_41.jpg][/div][/div][/div]
[div][/div][div][/div][div]補充一下，這是我另外做的 DepthWriteSpriteShader ，要有深度寫入才能做到 Sprite 穿插效果。[/div]
[div][/div][div][/div][div]除此之外，視覺容器除了控制 billboard 效果之外，也是動畫播放的接口，因為有揮動武器的需求（需要有 Transform 錨點），所以動畫方案是 Unity Animation，但沒有使用 Animator 狀態機，而是直接用名稱指定播放的動畫。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_42.jpg][/div][/div][/div]
[div][/div][div][/div][div]我外掛一個動畫同步器給狀態機，他就會根據當前狀態自動選擇動畫播放。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_44.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]動畫的播放進度是這個 Addon 指定的，但因為我把狀態機設定成 FixedUpdate Tick，所以為了確保動畫播放正常，Play 要在 Monobehavior 的 Update 中調用才行。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_45.jpg][/div][/div][/div]
[div][/div][div][/div][div]順帶一提 ，雖然 State 本身要用專門的 Tick 更新，但 Addon 可以兼容 Monobehavior 的生命週期 ，Input 參數也是在 Update 寫入狀態機的。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_46.jpg][/div][/div][/div]
[div][size=4][b]背包 ( < 5% AI）[/b][/size][/div][div]剛開始有用 AI ，但發現遊戲好像不用太複雜的背包系統，所以還是自己寫了個簡化的。就是一個很簡單的背包，能撿起所有實做 IPickable 的物體。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_47.jpg][/div][/div][/div]
[div][/div][div][/div][div]然後掛一個撿物件的 Addon 給狀態機，當 IntentPick = true 時，進行簡單的 overlap 檢查週圍有沒有可以檢的物件，有的話就撿起來放進背包。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_48.jpg][/div][/div][/div]
[div][size=4][b]武器 ( < 5% AI）[/b][/size][/div][div]然後是關鍵的武器，因為涉及很多整合工作，所以也是自己寫。[/div]
[div][/div][div][/div][div]原本要寫新的武器腳本，但想一下發現能直接沿用狀態機框架，給武器閒置、飛行、撿起、卡住、揮動跟拿著的狀態，透過狀態機管理武器的行為。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_49.jpg][/div][/div][/div]
[div][/div][div][/div][div]最後整合玩家行為狀態機，加上撿武器跟投擲的狀態，然後呼叫背包把有 IPickable 的武器丟出去。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_50.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]武器撞到有 IStuckable 的目標會卡在對方身上，如果玩家這時去撿武器，就會連敵人一起拿起來。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_5.jpg][/div][/div][/div]
[div][/div][div][/div][div]做這類整合工作的速度就降低很多，畢竟是自己進行的，沒辦法像 AI 一分鐘幾百行。[/div]
[div][/div][div][/div][div]但也是必要的，可能是需求更加客製化、系統交互更複雜了，把所有前提資訊跟 AI 說清楚可能導致 Context 過長爆走，但不說清楚 AI 又沒辦法正確整合，所以自己來還是比較穩妥。[/div]
[div][size=4][b]場景輔助工具 （70% AI）[/b][/size][/div][div]有些全域系統不能用靜態初始化，需要一個場景實例，剛開始學到的方法就是 Prefab + Don't Destroy on Load + Singleton 吧，但以現在的程度已經[s]看不上[/s]不適合這種方案了。[/div]
[div][/div][div][/div][div]我比較喜歡用多場景管理共用系統，測試時只要記得把一個初始化系統的場景拉進 Hierarchy 就好，這樣我在很多的痾…手動的單元測試？場景就能共用這些系統。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_51.jpg][/div][/div][/div]
[div][/div][div][/div][div]但要自己拉場景還是好麻煩==[/div]
[div][/div][div][/div][div]所以也讓 GPT 給我搞了自動場景載入，用 [RuntimeInitializeOnLoadMethod] 在初始化階段觸發 static 函式，抓資料夾中的配置 ScriptableObject，用 Additive 模式載入要求的場景。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_52.jpg][/div][/div][/div]
[div][/div][div][/div][div]這樣就算我直接進 Play Mode，系統也會自動載入我要求的場景。一個簡單的 QOL 系統，GPT 幾分鐘就生好了，但我還是多花了一些時間修重複載入或啥的 bug。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_53.jpg][/div][/div][/div]
[div][size=4][b]DI 半自動注入（95% AI）[/b][/size][/div][div]從大量用 Interface 抽象化和依賴注入 DI 後，我就在想要不要學 Zenject 之類的自動注入框架，不然每次手動注入也是真的麻煩。[/div]
[div][/div][div][/div][div]不過 Zenject 是一個蠻大的系統，雖然功能很完善但相對要學的東西就更多。[/div]
[div][/div][div][/div][div]現階段好像也沒必要到一定要學？[/div]
[div][/div][div][/div][div]所以我轉念一想，反正需求也還不複雜，不如讓 GPT 給我個簡單的方案試水溫。總之先要求了幾種方案，然後指定我要的方向深入解釋。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_55.jpg][/div][/div][/div]
[div][/div][div][/div][div]剛開始的方案有嚴重過度設計，所以也要他簡化。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_56.jpg][/div][/div][/div]
[div][/div][div][/div][div]但 DI 自動注入是在目前能力邊界之外的知識 ，所以我追問了一些問題，然後要 GPT 給我解釋完整的自動注入流程。總之就是透過反射查找帶有 [Inject] Attribute 的變數，然後讓某個注入器傳入參考。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_57.jpg][/div][/div][/div]
[div][/div][div][/div][div]看完解釋思路就清楚多了，也知道怎麼使用這個簡易注入器。（對，原本是在連用都不會的知識邊界外）[/div]
[div][/div][div][/div][div]最終用法很簡化，首先在系統初始化把全域的服務註冊進一個 DI 容器，像是各種 Factory, Feedback 或 InputSystem。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_58.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]然後物件初始化時，把要注入的物件跟 DI 容器傳入注入器，反射會自動抓有 [Inject] 的欄位，根據先前註冊的 Interface 傳入實例，達成自動註冊。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_59.jpg][/div][/div][/div]
[div][/div][div][/div][div]也可以直接繼承一個自動注入 MonoBehavior，他會在基底 Start 自動注入，子類可以繼承 override  然後調用 base.Start()。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_60.jpg][/div][/div][/div]
[div][/div][div][/div][div]雖然這樣好像跟手動調用 Inject 沒區別就是了==[/div]
[div][/div][div][/div][div]至於為什麼不是在 Awake 注入？[/div]
[div][/div][div][/div][div]因為場景載入時機的問題，雖然搞了一個編輯器模式下的自動場景載入，但額外載入的場景「無論如何」都會比預設的 Active Scene 還晚初始化。[/div]
[div][/div][div][/div][div]所以進入 Play mode 的當下，測試場景的物件會比自動載入的初始化場景早 Awake ==[/div]
[div][/div][div][/div][div]這在有正常遊戲流程的情況下不會發生，但我不想老早處理整個流程，所以乾脆維持在 Start 注入。[/div]
[div][/div][div][/div][div]也有嘗試修過，但找到的方案反而都會失去自動載入的便利性，像是整個 Hierarchy 被摺疊起來之類的==[/div]
[div][/div][div][/div][div]所以算了，反正夠用 :P[/div]
[div][size=4][b]技能系統框架（80% AI）[/b][/size][/div][div]遊戲最核心的部分之二，也是繼狀態機之後第二大的框架。[/div]
[div][/div][div][/div][div]玩家串起敵人的玩法除了視覺和數值效果外，還能使用敵人的能力（類似卡比之星那樣），所以我需要一套能在敵人、武器之間通用的技能系統。[/div]
[div][/div][div][/div][div]總之先大概描述需求，然後把專案結構給 GPT 看，要他提出幾種方案。然後針對比較符合的方案，要求進一步解說和案例。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_61.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]技能系統我做了三版，第一版是依據 GPT 給的方案 D 實作，但複製到專案中發現整合不了，因為跟需求有些偏差，它提的插槽概念比較像多個 Modifier ，能對技能添加額外效果。[/div]
[div][/div][div][/div][div]但我只需要「整個」技能能被武器拿去用。[/div]
[div][/div][div][/div][div]所以我寫了一些比較貼近預期的 interface 架構給 GPT，要他修正設計方向，然後就有了第二版。[/div]
[div][/div][div][/div][div]第二版就符合需求了，貼到專案中就能實作出需要的功能，也成功實現了測試用的效果。但要整合的時候發現 OverDesign 太蠻，框架到實作之間多了一層沒必要的泛型型別轉換。[/div]
[div][/div][div][/div][div]所以我開始砍，再把簡化後的架構丟給 GPT，要他接續提供方案。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_62.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]於是就有第三版的技能框架了，也是最後採用的方案。（前兩版的對話都刪了，只有一開始就截到的圖能用 QQ）[/div]
[div][/div][div][/div][div]首先是技能的基本定義跟基本參數，用來讓使用者定義不同技能。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_63.jpg][/div][/div][/div]
[div][/div][div][/div][div]SkillBase 是技能效果的基底，<TDef> 代表這個技能要使用的定義類別，繼承一個 ISkillCore 作為使用接口，隱藏泛型。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_64.jpg][/div][/div][/div]
[div][/div][div][/div][div]ISkillContext 用來傳遞施放技能需要的參數、環境資訊或是工廠，例如包括施放者，施放目標位置、具體的施放目標，屬性修改器，還有針對每個專案實作註冊的施放資源跟補充資料。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_66.jpg][/div][/div][/div]
[div][/div][div][/div][div]最後是一個負責管理的 SkillHost，每個能使用技能的實例都有獨立的 Host，裡面會儲存他能用的各種 Skill 以及動態 （IDebugInfo 是方便除錯用的）[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_67.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]施放流程 會先檢查技能存不存在、是不是在冷卻，然後觸發技能的目標選擇器，最後讓技能自己檢查當前狀況符不符合發動條件[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_68.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]用法像這樣，建立一個 Host 之後，傳入專案需要的 Context ，用工廠建立技能實例，把技能添加到 Host 中，Host 會回傳一個 id ，後面就可以透過這個 id 施放技能。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_69.jpg][/div][/div][/div]
[div][/div][div][/div][div]還有單元測試，用一系列 Dump 系統檢查框架的基本功能。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_70.jpg height=350][/div][/div][/div]
[div][size=4][b]整合技能系統（< 5% AI）[/b][/size][/div][div]有技能系統框架後先進行一些測試的實作跟整合，先定義了兩個簡單的技能，Print Log 還有發射子彈。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_71.jpg][/div][/div][/div]
[div][/div][div][/div][div]實作子彈技能，從 Context 取得施放者和目標位置，把方向資訊寫入 Context、判斷發動條件、最後發動，透過 context 中提供的工場生成子彈並發射。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_72.jpg][/div][/div][/div]
[div][/div][div][/div][div]然後把人物狀態機補上施放技能的狀態，還有觸發技能的 Addon。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_73.jpg][/div][/div][/div]
[div][/div][div][/div][div]最後把玩家輸入 addon 替換成隨機行為的 addon，遊戲敵人的樣子也有了。角色發射的那個大球就是技能。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_2.jpg][/div][/div][/div]
[div][/div][div][/div][div]啊對也補充一下，我的狀態機實作中不包括邏輯角色（AI、玩家輸入），人物或敵人的狀態機只用來管理可執行行為之間的邏輯跟轉換條件。[/div]
[div][/div][div][/div][div]遊戲 AI 或邏輯可以用 Addon 掛載的方式運作，所以方案也不綁死，可以掛玩家輸入、簡單的隨機行為、另一個 AI 狀態機或是串外部的行為樹插件當決策大腦。[/div]
[div][size=4][b]武器技能系統（< 10% AI）[/b][/size][/div][div]為了使用敵人技能，武器也是跟相同的技能系統整合，所以效果都直接兼容。但整合時發現一些需求缺陷，所以也讓 GPT 提供一些修正方案。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_74.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]建立一個武器專用的技能 Host，可以把技能加給武器，然後註冊技能的發動時機。發動時機是狀態機的 State。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_75.jpg][/div][/div][/div]
[div][/div][div][/div][div]再把一個發動技能的 Addon 掛到武器 StateMachine 上，每當進入新的 State 時他就會發出一個技能的訊號，如果有註冊的技能就會自動發動。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_77.jpg][/div][/div][/div]
[div][/div][div][/div][div]玩家撿一把帶有發射技能的武器，揮擊就會發射子彈，幾次沒發射是因為在冷卻。阿子彈直接穿過怪物是因為我還沒實作真的射彈系統，現在只是測試技能用的。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_3.jpg][/div][/div][/div]
[div][size=4][b]整合讓武器串起敵人（< 1% AI）[/b][/size][/div][div]最後，也是最重要的，讓玩家把敵人串起來。原本是打算讓武器複製敵人的技能，還有建立一個視覺副本，但實際整合的時候發現最好的做法其實是「整碗端去」。[/div]
[div][/div][div][/div][div]就是直接把整個敵人物件轉移到武器底下的意思。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_78.jpg][/div][/div][/div]
[div][/div][div][/div][div]雖然機制還沒設計完整，但在預期構想中，被串上武器的敵人實際上還是「活著」的，除了會在玩家揮動時發動技能效果、會在武器上講一些垃圾話，還可能在某個時機被噴飛回場地中。[/div]
[div][/div][div][/div][div]整個敵人捕捉的好處就是，我不用特別寫複製品的程式，敵人的行為接口都是能直接調用的，播放動畫、技能、甚至後面的講話功能。[/div]
[div][/div][div][/div][div]那敵人原本的行為怎麼辦？我讓目標繼承一個 ICapturable 介面，實作被捕捉時的反應，直接把碰撞箱、物理和狀態機關閉就好了。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_79.jpg][/div][/div][/div]
[div][/div][div][/div][div]而且，敵人被捕捉當下的動態參數也會被沿用，例如技能冷卻、施放次數之類的，如果玩家把怪物的技能次數用完，那怪物被噴回場地後也放不了技能。[/div]
[div][/div][div][/div][div]至於捕捉功能就用一個管理系統，在玩家撿起卡住的武器時調用，就會把整個敵人搬起來。觸發介面的 OnCaptured，然後調用前面視覺容器寫過的功能，把敵人轉移到武器底下，並縮小顯示夾角。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_80.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]嗒啦，吃毒的遊戲核心架構就有了，可以看到每多黏一個敵人，玩家揮砍時射出的子彈就多一顆，每顆都是不同敵人各自技能發射的。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_9.jpg][/div][/div][/div]
[div][/div][div][/div][div]而且所有行為都是雙向兼容，玩家跟敵人的的運作方式是相同的。[/div]
[div][/div][div][/div][div]我是說，完全相同。[/div]
[div][/div][div][/div][div]意思是，如果玩家被武器丟到，敵人也能把玩家撿起來  (ﾟ∀。)[/div]
[div][/div][div][/div][div]總之程式也算暫時告一段落？因為已經撞到設計進度了，要先回去補完企劃才能繼續 ==[/div]
[div][/div][div][/div][div]我們現在甚至連一份文件都還沒寫，只有 Mrio 上的討論紀錄而已，專案管理也是超簡陋的 Excel 表隨便列。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_81.jpg][/div][/div][/div]
[div][/div][div][/div][div]然後兩週後就要交一審資料，應該還能再補一些東西，阿來不及就算了，但企劃…多啦 GPT 夢，幫我寫企劃書啦 (´;ω;`)[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_82.jpg][/div][/div][/div]
[div][size=5][b]結論[/b][/size][/div][div]從開始寫畢專程式到完成控制、武器或技能什麼的整合大概花了三週（8/14 ~ 9/4），包括假日。工時不穩定，一天三到十小時都有可能。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_83.jpg][/div][/div][/div]
[div][/div][div][/div][div]以核心功能的原型來說，應該算合理的時間？[/div]
[div][/div][div][/div][div]不過這種時間壓力下可能只做的出拋棄式的屎山，就是 GameJame 會寫的那種，所以通常情況我還得整個打掉，重新架構、設計後再開發一次。[/div]
[div][b]※架構[/b][/div][div]但這次不是拋棄式的程式，而是一開始就有照顧維護性、擴展性的架構。[/div]
[div][/div][div][/div][div]這次沒用什麼 DDD 或 Clean Code （至少目前沒） ，只是把程式分成兩大部份，一部分是相互獨立的可重用框架，另一部分則是針對專案需求的實作與整合。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_84.jpg][/div][/div][/div]
[div][/div][div][/div][div]可重用框架包括狀態機、回饋、帳簿與技能系統。名稱後綴 .Core 代表純 C# 的核心程式碼，.Unity 代表有對 Unity 的依賴，.Test 代表單元測試，其他名稱 (MMFeelFeedback) 代表對某些外部模組或插件的依賴。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_85.jpg][/div][/div][/div]
[div][/div][div][/div][div]可重用框架的重點是框架本身，用一系列抽象接口定義系統架構，但不提供「具體」實作，尤其是 Core。[/div]
[div][/div][div][/div][div]可能會補充一些常用或好用的方案（像 Feel 插件的串接），但最重要的是，無論這裡怎麼提供方案，每個專案都可以替換或實作自己需要的方案，框架只是指引而非限制。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_86.jpg][/div][/div][/div]
[div][/div][div][/div][div]這就是 SOLID 的力量嗎…八年了，從開始接觸程式八年了，總算讓我見識到物件導向的真諦了。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_88.jpg height=350][/div][/div][/div]
[div][b]※能力[/b][/div][div]果然還是程式做起來最自在啊，當初是覺得企劃太重要得自己來，所以才另外找程式組員，但經過各種混亂之後，現在看來還是自己做程式最好。[/div]
[div][/div][div][/div][div]當然，企劃是重要沒錯，但我嚴重高估了自己做企劃、專案管理的能力跟心力。[/div]
[div][/div][div][/div][div]雖然之前日誌寫了蠻多企劃跟 PM 的紀錄，但我得說，那些文書工作對我來說真的很吃力，而且幾乎沒有進入「心流」狀態過。現在是盡可能把企劃、PM 或文書工作分攤出去，要再像三專那樣搞是不可能了，我受不了。[/div]
[div][/div][div][/div][div]除此之外，我也嚴重低估自己作為程式的重要性，或許這就是達克效應吧，自身的兩項專業恰好在線段的兩端。還有那些從小累積的自卑、缺乏關注的問題也是原因，但現在都面對的差不多了。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_89.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]雖然思考或講話時還是會有那些影子在，但至少能從日誌開始改變吧，在文字上表現的對自己有自信點，再慢慢改變現實的自己。[/div]
[div][/div][div][/div][div]當然，不可能做到完美，但沒必要把那些缺點放大到像自己一無是處一樣。[/div]
[div][/div][div][/div][div]其實之前就發現我的程式能力不斷卡到相同的瓶頸，一直蠻挫折的，但現在明白也只是知識邊界不夠廣而已，我的經驗值絕對夠了，只是很多重要的知識根本就沒解鎖。[/div]
[div][/div][div][/div][div]自學的缺點就是知識會學的很破碎吧，畢竟從最初開始就沒人系統性的教過我東西，也沒去上課，知識都是從網路、朋友和前輩那裡乒湊出來的。（我不喜歡看書學可能是一大原因，看書的話應該也能蠻有系統的學）[/div]
[div][/div][div][/div][div]直到從去年開始增加接觸 ChatGPT 的頻率，當時的【學習】日誌裡面就開始提到我用它幫自己學程式。[/div]
[div][/div][div][/div][div]而摸索到現在，也算找到適合自己的用法了。[/div]
[div][/div][div][/div][div]跟以前做事的速度相比，現在在 AI 輔助下效率「至少」翻了 3~5 倍，無論是專案開發、還是學習效率都是。暑假的 AI 研究真的值得，剛好在畢專前解鎖了一個超強技能的感覺。[/div]
[div][/div][div][/div][div]現在就像過去機攢的一切突然爆發，果然努力都是確確實實累積在自己身上的，第八年了啊…已經是我至今人生的 1/3 了。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_90.jpg][/div][/div][/div]
[div][/div][div][/div][div]上面那些用 AI 生的程式也都在我的能力範圍內，我自己寫的出來嗎？當然，但也不會比 AI 快，而累積的經驗也讓我知道就算自己寫也不見得能比 AI 好。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_4.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]因為經驗夠，所以能判斷我要什麼，生成的程式也幾乎一看就懂了。[/div]
[div][/div][div][/div][div]但在看到之前，我也不知道有還有這些做法。[/div]
[div][/div][div][/div][div]經驗跟能力夠，只是有些重要的東西「還」不知道而已，這就是知識邊界造成的限制，還有之前瓶頸的成因。[/div]
[div][/div][div][/div][div]我沒有一個個點出來，但過程真的填補了很多零碎的知識空缺，像是自動注入方式，而因為前提知識也都夠了，所以聽 GPT 解釋也很快就懂。（之後會把零碎知識也記錄下來）[/div]
[div][/div][div][/div][div]唯一真正超出能力邊界的就是單元測試了，感覺該會的基礎知識都有了，但就是不知道「何時」或「該不該」寫測試。[/div]
[div][/div][div][/div][div]因為這種判斷就是經驗問題，除了花時間累積以外別無他法。[/div]
[div][b]※ AI[/b][/div][div]最後談回 AI，再強調一次開頭的結論。[/div]
[ul]
[li]在目標與意圖足夠明確時，AI 寫程式除了快之外還能寫比我好[/li]
[li]讓 AI 幫忙主要是為了提高效率而已，自己還是要有能力解決問題[/li]
[li]利用 AI 可以很激進的擴展能力（知識）邊界[/li]
[li][b]自身的能力與知識邊界就是 AI 的表現邊界[/b][/li]
[li][b]可以利用 AI 擴展自身能力邊界，再讓 AI 用瘋狂的效率完成自己能力邊界内的工作，產生一種正循環[/b][/li]
[/ul]
[div][/div][div][/div][div]目前為止， AI 程式碼與手工程式碼大約各占 50%，AI 主要負責各種相互獨立的模組系統「框架」，自己則是針對遊戲需求進行實做與各系統的整合，不同項目標註的比例也能反映出這點。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_91.jpg height=350][/div][/div][/div]
[div][/div][div][/div][div]左半部更加單元化、模組化的工作可以讓 AI 表現的很精準，因為目標跟解決方案都很明確，需要的前提資訊不複雜，失敗重來的成本也更低。[/div]
[div][/div][div][/div][div]右半整合工作因為是專案的課製化需求，並且涉及多個系統的交互，光是把必要資訊告訴 AI 之後 Context 就會到達不穩定的長度了，所以還是自己來比較可靠。（至少我目前是這樣，之後更熟說不定能找到方式克服）[/div]
[div][/div][div][/div][div]而 95% 的 AI 程式碼是 ChatGPT 寫的，其他 CodexCLI, GeminiCLI, Copilot Agent 總計不到 5%。[/div]
[div][/div][div][/div][div]因為 ChatGPT 的程式碼是寫在聊天串中，我可以從討論方案開始，先看程式碼評估是不是我需要的，然後提出疑問，等結果比較確定後再貼到專案中：[/div]
[ul]
[li]簡單描述需求，讓 GPT 提出多種方案[/li]
[li]自己評估哪種方案適合，要不要混合方案[/li]
[li]讓 GPT 針對指定方案提出一些實做案例，或開始生成[/li]
[li][b]如果生成內容超出知識邊界，讓 GPT 進一步解釋原理[/b][/li]
[li]檢查生成內容，評估是不是符合需求，有沒有缺少或過度設計，讓 GPT 調整[/li]
[li]把程式碼貼到專案中，然後根據專案修改和二次評估，如果理想就繼續沿用[/li]
[li]如果不理想，先用自己的意思把程式碼整理後，再丟給另一個對話串接續[/li]
[li][b]視情況回到前面的某個步驟，重複循環直到結果貼近自己預期的樣子，或在某個時機接手修改[/b][/li]
[/ul]
[div][/div][div][/div][div]讓 CodexCLI, GeminiCLI 或 Copilot Agent 直接寫進文件是快沒錯，但也不知道為什麼，[b]我發現大腦要消化直接生進文件的程式碼是很吃力的事。[/b][/div]
[div][/div][div][/div][div]但跟多了跟 GPT 討論 + 複製貼上就能很大程度克服這問題，而降低理解門檻也等於更快的推進知識邊界，所以至少目前我還是偏好用 ChatGPT。[/div]
[div][/div][div][/div][div]所以[/div]
[div][/div][div][/div][div]說了這麼多，難道我也要開始推銷線上課程了嗎？[s]現在加入享一折優惠歐[/s][/div]
[div][/div][div][/div][div]沒，雖然這整篇看起來都是安麗，但我也沒有要特別鼓吹或勸退誰[/div]
[div][/div][div][/div][div]因為這次的情況真的比較複雜了，所以首先要強調，[b]請不要把這篇文提到的東西當做指南或建議[/b]，尤其我知道有些系上的程式同學會看我的文，但我無法保證你們用相同的手段會不會有效…[/div]
[div][/div][div][/div][div][b]或甚至會不會有負面影響。[/b][/div]
[div][/div][div][/div][div]與一般情況下的學習不同，你學的任何東西都會慢慢累積在自己身上，這是加法，雖然數字可能很微小，但都是確實在累積的。[/div]
[div][/div][div][/div][div][b]但 AI 是某種指數的乘法，基數為你的當前的能力和知識水平。[/b][/div]
[div][/div][div][/div][div]所以，在能力大過某個門檻之前，不管怎麼乘都只會有反效果，而我已經離開那段的範圍了，現在也無法判斷自己會的一切對其他初學者來講會是幫助還是負擔。[/div]
[div][/div][div][/div][div][b]而我也不清楚自己身上會不會累積某種長期的負面影響。[/b][/div]
[div][/div][div][/div][div]雖然 AI 更加普及了，但也開始出現各種研究報告示警大眾，依賴 AI 可能對大腦產生某些不可逆的影響，「削弱思考能力」「認知負債」「創造、記憶、回憶的區塊退化」等等。[div][div align=center][img=https://raw.githubusercontent.com/angus945/diary-archive-publish/refs/heads/main/post-2025/post-2025_09_05-learn-graduation-prototypes_and_the_insane_efficiency_of_AI/image_92.jpg][/div][/div][/div]
[div][/div][div][/div][div]我能明顯的感覺大腦的思維模式產生什麼變化，變得更依賴 AI 提供建議，思考某些事情的意願降低了，或顯得更吃力，而且變不回去了。[/div]
[div][/div][div][/div][div]我也沒辦法說清楚，自己所謂的「擴展能力邊界」究竟是真的有内化那些知識，還是資訊取得過於容易而產生的假象？[/div]
[div][/div][div][/div][div]或許我已經在透支什麼了也說不定？[/div]
[div][/div][div][/div][div]但發生就是發生了，現在也不可能折返，我就寫在這裡，把現在的想法記錄下來，或許未來的哪天會產生什麼作用也說不定。[/div]
[div][/div][div][/div][div]總之[/div]
[div][/div][div][/div][div]AI 對我來說真的很方便，但無論如何，有些底線還是要自己堅守著。[/div]
[div][/div][div][/div][div]即使有 AI，這些日誌的內容我也會靠自己寫。[/div]
[div][/div][div][/div][div]一字一句的慢慢寫下。[/div]
[div][/div][div][/div][div]現在是[/div]
[div][/div][div][/div][div]之後也是 :)[/div]
[div][/div][div][/div][div]---[/div]